{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Rough Skeleton of Working Draft\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Table of Contents:\n",
    "1. Sypnosis\n",
    "    - Research Question\n",
    "    - Summary\n",
    "<p></p>\n",
    "2. Selection of Data \n",
    "    - Packages Used\n",
    "    - Loading and Cleansing\n",
    "<p></p>\n",
    "3. Training, Validation, and Testing Sets\n",
    "    - Compartmentalization\n",
    "    - Summary Statistics\n",
    "<p></p>\n",
    "4. Preprocessing \n",
    "    - Indetification of Class Imbalances\n",
    "    - Balancing Decision\n",
    "<p></p>\n",
    "5. Building our Model\n",
    "    - Overview \n",
    "    - Tuning\n",
    "    - Accuracy Comparison\n",
    "<p></p>\n",
    "5. Analysis and Conclusion\n",
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Sypnosis: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Research Question:\n",
    "How can an author increase engagement from users on Facebook and can we predict the success of a post using insights from an author's page?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overview:\n",
    "<p></p>\n",
    "The market utility of social media platforms such as Facebook, which are able to generate mass revenues for cosmetic brands, has been an established and exploited advertising strategy in the digital age (Moro et. al, 2016). The goal of this project is to take a predictive analytical approach to determine which type of Facebook post (i.e., photo, video, status, or link) will engage the most internet-user engagement, determined through variables such as likes, post consumptions, and post total reach. The dataset which will be used for this analysis was acquired through an experimental data mining technique which included scraping data from the Facebook page of an internationally renowned cosmetics company on posts made between January 1st and December 31st (Moro et. al., 2016).\n",
    "<p></p>\n",
    "For the methodology, we will use the variables of the continuous numerical variables of total reaches (Lifetime_Post_Total_Reach) and the number of total impressions (Lifetime_Post_Total_Impressions), and the categorical variable of Facebook post (Type). First, we will look at the relationship between these variables in a scatter plot graph that will help us to formulate our hypothesis. Then, as we are trying to predict the type of post that will be the most successful, we will use a K-nearest neighbour classification analysis. To do so, we must determine the K value using cross-validation of the training data. Then, we will need to test the accuracy of the classifier with the testing data.\n",
    "<p></p>\n",
    "We expect to find that posts which include media, such as photos and videos, are more likely to engage users than other posts, such as statuses and links. This is based on the assumption that the former types of posts might be more likely to be shared and thus will have more exposure.\n",
    "It is beneficial for social media platforms to increase user engagement, as this is likely to increase revenue through advertising. Therefore, these findings may be used to choose what type of posts are prioritized to maximize user engagement.\n",
    "<p></p>\n",
    "These findings may lead to further exploration of how the contents of these posts impact user engagement. This may include the duration of a video, content of an image, length of a status, or details about the contents of a link. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Selection of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Packages Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"caTools\")\n",
    "library(caTools)\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(kknn)\n",
    "library(MASS)\n",
    "library(cowplot)\n",
    "library(ggplot2)\n",
    "options(repr.matrix.max.rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data and Fixing Column Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook <- read_csv2(\"https://raw.githubusercontent.com/calamari99/Facebook-Post-Predictor/main/data/dataset_Facebook.csv\")\n",
    "# Replacing specified columns to categorical factors\n",
    "cols <- c(\"Type\", \"Category\", \"Post Month\", \"Paid\", \"Post Weekday\", \"Post Hour\")\n",
    "facebook[cols] <- lapply(facebook[cols], as.factor)\n",
    "\n",
    "# Renaming column headers without spaces\n",
    "facebook_colname_fix <- facebook\n",
    "\n",
    "facebook_col_name_vec <- gsub(\" \", \"_\", colnames(facebook))\n",
    "colnames(facebook) <- facebook_col_name_vec\n",
    "\n",
    "glimpse(facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us select only the data values relevant to our case scenario\n",
    "\n",
    "To specify the best type of post possible and we explore the relationship between the metrics produced by a post and the post type. The following key performance indicators describe a post's success:\n",
    "- comments\n",
    "- likes\n",
    "- shares\n",
    "- total interactions (summation of the 3 observations above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_clean <- dplyr::select(facebook, Type, comment,\n",
    "                                like, share, Total_Interactions,\n",
    "                                Paid, Lifetime_Post_Total_Impressions, Lifetime_Post_Total_Reach) %>% na.omit(df)\n",
    "\n",
    "facebook_clean_unpaid <- facebook_clean %>% filter(Paid == 0)\n",
    "facebook_clean_paid <- facebook_clean %>% filter(Paid == 1)\n",
    "\n",
    "unpaid_summary <- facebook_clean_unpaid %>% group_by(Type) %>% \n",
    "  summarise(unpaid = n()) \n",
    "\n",
    "paid_summary <- facebook_clean_paid %>% group_by(Type) %>% \n",
    "  summarise(paid = n())\n",
    "\n",
    "Reduce(dplyr::full_join, list(unpaid_summary, paid_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within our 500 data points collected, we have filtered out all observations with NA values and separated our data into paid and unpaid categories due to additive relationships. This allows us to explore the relationship between post type and our defined success metric. Moving forward, this study will only evaluate on media postings without paid advertising.\n",
    "\n",
    "> Note: Social media algorithms that adjust prioritizations between paid and non-paid posts can heavily factor into our metrics received and should be considered in this analysis. To control for this potential source of uncertainty, we haved isolated our data into paid and unpaid categories. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Training, Validation, and Testing Sets \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compartmentalization\n",
    "We have split our data into training and testing sets in order to reduce bias within our model data and testing data. \n",
    "\n",
    "*Distribution of Training and Testing set*\n",
    "<br>\n",
    "Testing set will be 20% of data collected\n",
    "<br>\n",
    "Validation set will be 10% of data collected\n",
    "<br>\n",
    "Training data set be 70% of data collected\n",
    "\n",
    "*Cross-validation technique*\n",
    "<br>\n",
    "let us split our data into 10 total groups.\n",
    "<br>\n",
    "(~25 points tested, 100 points for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to approach our training data by creating a 80:20 ratio between testing and training data where the  training set is composed of both the “validation” and “training” set. We have also chosen a 10-fold cross-validation procedure to establish unbiased estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Variables\n",
    "set.seed(99)\n",
    "partitionTrain = 0.8\n",
    "ratioTrainValidation = 7/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 ratio TrainingSet:TestingSet\n",
    "split <- sample.split(facebook_clean$like, SplitRatio = partitionTrain)\n",
    "train_val_data <- subset(facebook_clean, split == TRUE)\n",
    "test_set <- subset(facebook_clean, split == FALSE)\n",
    "\n",
    "split <- sample.split(train_val_data$like, SplitRatio = ratioTrainValidation)\n",
    "train_set <- subset(train_val_data, split == TRUE)\n",
    "val_set <- subset(train_val_data, split == FALSE)\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpaid Posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split <- sample.split(facebook_clean_unpaid$like, SplitRatio = partitionTrain)\n",
    "train_val_data_unpaid <- subset(facebook_clean_unpaid, split == TRUE)\n",
    "test_set_unpaid <- subset(facebook_clean_unpaid, split == FALSE)\n",
    "\n",
    "split <- sample.split(train_val_data_unpaid$like, SplitRatio = ratioTrainValidation)\n",
    "train_set_unpaid <- subset(train_val_data_unpaid, split == TRUE)\n",
    "val_set_unpaid <- subset(train_val_data_unpaid, split == FALSE)\n",
    "\n",
    "#glimpse(train_set_unpaid)\n",
    "train_set_unpaid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Training Data Summaries\n",
    "\n",
    "- Number of observations of each type\n",
    "- Mean and Median of key metrics in each post type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary of Unpaid Posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_train_unpaid <- train_set_unpaid %>%\n",
    "    group_by(Type) %>%\n",
    "        summarise(\n",
    "        count = n(),\n",
    "        mean_comment = mean(comment), \n",
    "        median_comment = median(comment), \n",
    "        mean_like = mean(like),\n",
    "        median_like = median(like),\n",
    "        mean_Total_Interactions = mean(Total_Interactions),\n",
    "        median_Total_Interactions = median(Total_Interactions),\n",
    "        mean_share = mean(share),\n",
    "        median_share = median(share),\n",
    "    )\n",
    "\n",
    "summ_train_unpaid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### 4.) PreProcessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indentification of class imbalances\n",
    "We want to be able to identify possible class imbalances as the KNN-classification model is a lazy learning algorithm. Thus we need to ensure that our data set is balanced. We start by reviewing summary statistics and quickly visualizing the distribution of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(train_set_unpaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=20)\n",
    "test_unpaid_hist_1 <- train_set_unpaid %>%\n",
    "    ggplot(aes(fill=Type, x=Lifetime_Post_Total_Reach/100))+\n",
    "    geom_histogram(binwidth=20,center = 1,boundary = NULL,alpha=0.7,position=position_stack(vjust=0, reverse=FALSE))+\n",
    "    labs(x=\"Total reach (hundreds)\", fill=\"Type of post\")+\n",
    "    scale_x_continuous(limits = c(0,600))+\n",
    "    scale_fill_manual(values = c(\"#eb1515\", \"#15eb15\", \"#1515eb\", \"#eb8015\"))+\n",
    "    theme(text = element_text(size = 16))\n",
    "test_unpaid_hist_2 <- train_set_unpaid %>%\n",
    "    ggplot(aes(x=Lifetime_Post_Total_Impressions/100, fill=Type))+\n",
    "    geom_histogram( stat = \"bin\", alpha=0.7,position=position_stack(vjust=0, reverse=FALSE))+\n",
    "    labs(x=\"Total impression (hundreds)\", fill=\"Type of post\")+\n",
    "    scale_fill_manual(values = c(\"#eb1515\", \"#15eb15\", \"#1515eb\", \"#eb8015\"))+\n",
    "    scale_x_continuous(limits = c(0,600))+\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_grid(test_unpaid_hist_1,test_unpaid_hist_2, ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing Decision\n",
    "We see the distribution of the type of posts is not equal so we should consider balancing. However, this introduces potential complications in further parts of our analysis, mainly the cross validation step. We find that balancing our data in this part of our analysis results in overestimated accuracies for our cross validation model later on. Additionally, we are hestitant to balance training set because this alternation is not reflected in our testing set, which can lead to more uncertainty. Because of these factors, we chose to leave our data unbalanced. We believe this will lead to less biased results when using our training data set further in our report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Building our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "We use the original training data into our tuning selection process. Then by scaling the data and following the tidymodel recipes workflow, we collect the results from various values of k. Our base value of k is set to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "unpaid_recipe <- recipe(Type ~ \n",
    "                        Lifetime_Post_Total_Reach + Lifetime_Post_Total_Impressions,\n",
    "                        data = train_set_unpaid) %>%\n",
    "  step_scale(all_predictors()) %>%\n",
    "  step_center(all_predictors())\n",
    "\n",
    "unpaid_fit <- workflow() %>%\n",
    "      add_recipe(unpaid_recipe) %>%\n",
    "      add_model(knn_spec) %>%\n",
    "      # fit(data = upsampled_cancer)\n",
    "      fit(data = train_set_unpaid)\n",
    "\n",
    "      #fit_resamples(resamples = unpaid_vfold)\n",
    "\n",
    "unpaid_val_predicted <- predict(unpaid_fit, val_set_unpaid) %>%\n",
    "    bind_cols(val_set_unpaid)\n",
    "\n",
    "unpaid_prediction_accuracy <- unpaid_val_predicted %>%\n",
    "    metrics(truth = Type, estimate = .pred_class)\n",
    "    \n",
    "unpaid_prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that our current accuracy against our validation set is roughly 75%. We will continue to tune our model in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We will perform the cross validation technique with 10 folds to account for randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(99)\n",
    "#unpaid_vfold <- vfold_cv(upsampled_cancer, v = 10, strata = Type)\n",
    "unpaid_vfold <- vfold_cv(train_set_unpaid, v = 10, strata = Type)\n",
    "\n",
    "unpaid_fit_v2 <- workflow() %>%\n",
    "      add_recipe(unpaid_recipe) %>%\n",
    "      add_model(knn_spec) %>%\n",
    "      fit_resamples(resamples = unpaid_vfold) %>% collect_metrics()\n",
    "unpaid_fit_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the accuracy of our model is around 86%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next we will perform a paramterization selection method to select a better value for K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "knn_results <- workflow() %>%\n",
    "  add_recipe(unpaid_recipe) %>%\n",
    "  add_model(knn_tune) %>%\n",
    "  tune_grid(resamples = unpaid_vfold, grid = 10) %>% \n",
    "  collect_metrics()\n",
    "\n",
    "accuracies <- knn_results %>% \n",
    "       filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then using our collected metrics, we can visualize our accuracies to refine our value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=5)\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\", title = \"K-NN Classification Accuracy by Neighbors\") +\n",
    "      scale_x_continuous(breaks = seq(0, 16, by = 2)) +  # adjusting the x-axis\n",
    "      scale_y_continuous(limits = c(0.8, 1.0)) # adjusting the y-axis\n",
    "\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_k <- knn_results %>% filter(.metric == \"accuracy\") %>% arrange(desc(mean)) %>% slice(1)\n",
    "most_accurate_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization suggests that K=4 averages the highest accuracy of ~86% from our 10 cross validation sets. We edit our model specification to take k=2 instead of k=3 as follows. After doing so, we can compare the accuracy of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the same recipe, change spec\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 4) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "unpaid_fit_tuned <- workflow() %>%\n",
    "      add_recipe(unpaid_recipe) %>%\n",
    "      add_model(knn_spec) %>%\n",
    "      fit(data = train_set_unpaid) \n",
    "      #fit_resamples(resamples = unpaid_vfold)\n",
    "\n",
    "unpaid_val_predicted_tuned <- predict(unpaid_fit_tuned, val_set_unpaid) %>%\n",
    "    bind_cols(val_set_unpaid)\n",
    "\n",
    "unpaid_prediction_accuracy_tuned <- unpaid_val_predicted_tuned %>%\n",
    "    metrics(truth = Type, estimate = .pred_class) %>% filter(.metric == \"accuracy\")\n",
    "\n",
    "model_improvement <- unpaid_prediction_accuracy_tuned$.estimate - unpaid_prediction_accuracy$.estimate\n",
    "\n",
    "unpaid_prediction_accuracy_tuned\n",
    "print(model_improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing our model spec from 2 to 3, we see that the modifications to our model has increased our accuracy by roughly *5.56%* (our original accuracy was roughly *72.2%*) and thus we will choose the tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Comparison\n",
    "- We have limited video observation in our testing set\n",
    "- after we have classified the limited video observations, any prediction that classifies a video is incorrect\n",
    "- todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Analysis and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Additional Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_comment <- summ_train_unpaid$mean_comment\n",
    "mean_like <- summ_train_unpaid$mean_like\n",
    "mean_Total_Interactions <- summ_train_unpaid$mean_Total_Interactions\n",
    "mean_share <- summ_train_unpaid$mean_share\n",
    "type <- summ_train_unpaid$Type\n",
    "\n",
    "test_df <- data.frame(mean_comment,mean_like,mean_Total_Interactions,mean_share,type)\n",
    "test_df\n",
    "\n",
    "fb_long <- test_df %>%\n",
    "gather(\"Stat\", \"Value\", -type)\n",
    "\n",
    "fb_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df <- data.frame(\n",
    "# mean_comment = c(4.0, 7.317073, 13.166667, 12.333333),\n",
    "# mean_like = c(56.66667, 202.14634, 281.16667, 276.33333),\n",
    "# mean_Total_Interactions = c(71.0000, 235.2683, 353.8333, 346.6667),\n",
    "# mean_share = c(10.33333, 25.80488, 59.50000, 58.00000),\n",
    "# type = c(\"Link\", \"Photo\", \"Status\", \"Video\"))\n",
    "\n",
    "\n",
    "# fb_long <- test_df %>%\n",
    "# gather(\"Stat\", \"Value\", -type)\n",
    "\n",
    "# fb_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_mean_like <- fb_long %>%\n",
    "    filter(Stat == \"mean_like\")\n",
    "\n",
    "filter_mean_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 6) \n",
    "\n",
    "mean_likes_bar <- ggplot(filter_mean_like, aes(x = type, y = Value, fill=type)) +\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    labs(x = \"Post Type\", y = \"Average Number of Likes\") +\n",
    "    theme(text = element_text(size = 20)) \n",
    "mean_likes_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "mean_fb <- ggplot(fb_long, aes(x = type, y = Value, fill = Stat)) +\n",
    "    geom_col(position = \"dodge\") +\n",
    "    labs(x = \"Type of Post\", y = \"Count\") +\n",
    "    scale_fill_discrete(name = \"Stats\", labels = c(\"Mean Comment\", \"Mean Like\", \"Mean Share\", \"Mean Total Interactions\"))+\n",
    "    theme(text = element_text(size = 20))\n",
    "mean_fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_plot <- facebook_clean_unpaid %>% \n",
    "    ggplot(aes(x = Lifetime_Post_Total_Reach/100, y = Total_Interactions, shape=Type, color=Type, fill=Type))+\n",
    "    geom_point(alpha=0.6, size=4)+\n",
    "    labs(x=\"Total reach (hundreds)\", y=\"Total interactions\", group=\"Type\")+\n",
    "    scale_y_continuous(limits = c(0,900))+\n",
    "    scale_x_continuous(limits = c(0,500))+\n",
    "    scale_shape_manual(values = c(21,22,23,24)) +\n",
    "    scale_size_manual(values=c(1,6,7,9))+\n",
    "    theme_minimal()+\n",
    "    theme(text = element_text(size = 20))\n",
    "    options(repr.plot.width =14, repr.plot.height = 8) \n",
    "unpaid_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "Moro, S., Rita, P., & Vala, B. (2016). Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach. Journal of Business Research. 69(9), 3341 - 3351. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
